{"cells":[{"cell_type":"markdown","metadata":{"id":"ymxatB5WYxlL"},"source":["# Transformer 실습\n","\n","이번 실습에서는 감정 분석 task에 RNN 대신 Transformer를 구현하여 적용해 볼 것입니다.\n","\n","Library import나 dataloader 생성은 RNN 실습 때와 똑같기 때문에 설명은 넘어가도록 하겠습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1X7RM2du1zcr","outputId":"d55cac8d-975b-4f67-a2f0-6b09565650c1"},"outputs":[],"source":["!pip install datasets\n","!pip install ipywidgets\n","!pip install transformers\n","!pip install sentencepiece sacremoses importlib_metadata"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"HOdhoBVA1zcu"},"outputs":[{"name":"stderr","output_type":"stream","text":["Using cache found in /root/.cache/torch/hub/huggingface_pytorch-transformers_main\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["import torch\n","from datasets import load_dataset\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizerFast\n","from tokenizers import (\n","    decoders,\n","    models,\n","    normalizers,\n","    pre_tokenizers,\n","    processors,\n","    trainers,\n","    Tokenizer,\n",")\n","\n","ds = load_dataset(\"stanfordnlp/imdb\") # Large Movie Review Dataset from Hugging Face Hub\n","tokenizer = torch.hub.load('huggingface/pytorch-transformers', 'tokenizer', 'bert-base-uncased') # load bert model from github repo\n","\n","\n","def collate_fn(batch): # get texts and labels from a batch dataset\n","  max_len = 400\n","  texts, labels = [], []\n","  for row in batch:\n","    labels.append(row['label'])\n","    texts.append(row['text'])\n","\n","  texts = torch.LongTensor(tokenizer(texts, padding=True, truncation=True, max_length=max_len).input_ids) # bert tokenizer outputs input_ids index from bert vocabulary store.\n","  labels = torch.LongTensor(labels) # 64bit integer tensor\n","\n","  return texts, labels\n","\n","BATCH_SIZE = 64\n","\n","train_loader = DataLoader(\n","    ds['train'], batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn\n",")\n","\n","test_loader = DataLoader(\n","    ds['test'], batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn\n",")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([400])\n","tensor([  101,  2034,  2125,  1010,  3087,  2559,  2005, 15902,  1000,  9560,\n","         8048,  1000,  5988,  2008, 15173,  2070,  4066,  1997,  2591,  4471,\n","         2007, 15902,  4616,  1998,  3969,  6575, 13764,  8649,  5287,  2011,\n","         4056,  1010,  7861,  4140,  3512,  1010,  2540, 26675,  1996, 13102,\n","         7066,  1010,  3531,  2681,  2085,  1012,  2017,  2024, 18313,  2115,\n","         2051,  1998,  2166,  2003,  2460,  1010,  2175,  2156,  1996,  2047,\n","        24905, 12439,  3981,  8183,  8751,  3185,  1010,  2031,  1037,  2204,\n","         5390,  1010,  2175,  2041,  1004,  4965,  1037,  8893,  2482,  2030,\n","         5466,  2185,  2115,  4736, 11719,  2065,  2008,  2097,  2191,  2017,\n","         2514,  2488,  1010,  1998,  2681,  2149,  2894,  1012,  1026,  7987,\n","         1013,  1028,  1026,  7987,  1013,  1028,  2123,  1005,  1056,  2292,\n","         1996,  2341,  2718,  2017,  2006,  1996,  2126,  2041,  2593,  1012,\n","         1996,  9788, 13721,  2158,  2003,  1037,  3694,  1038, 15718,  3164,\n","         5469,  8680,  2915,  1999,  1996,  5949,  8653,  1997,  5858,  2011,\n","         1037,  2402,  1010,  2694,  5379,  3459,  1004,  3626,  1010,  1998,\n","         5936,  2993,  2007,  2019, 19748,  2040,  2003,  6086,  2000, 13576,\n","         8249,  3896,  1010, 17507,  2039,  1999,  1037,  2902,  1010,  1998,\n","         4858,  2008,  2010,  2303,  2003,  5622,  4226, 14116,  2006,  2032,\n","         2004,  2002,  7719,  2045,  3110,  2066,  1037, 14684,  8737,  1012,\n","         1996, 13721,  2158,  2003,  2209,  2011,  2028,  4074,  2128,  8237,\n","         1010,  2040,  2003, 20123,  2005,  2055,  1996,  2034,  2176,  2781,\n","         1997,  1996,  2143,  1012,  2021,  2320,  2002,  4627,  1051, 18153,\n","         2378,  1005,  2007,  6174,  6243,  1005,  1055,  9313,  2569,  3896,\n","         5789,  2002,  2062, 12950,  2242,  2017,  2453,  2424,  1999,  1037,\n","         9543,  1997, 12403,  2213,  2077,  2017, 12475,  2125,  2035,  1996,\n","         2448,  4890,  1010, 25292, 27199,  1038,  2571,  5910,  1997, 21956,\n","         1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  1996,\n","         2143,  2038,  5717, 13080,  1998,  2515,  2025,  2316,  2100,  2055,\n","         2007,  5436,  2685,  1024,  2045,  2024,  1037,  3232,  1997,  5019,\n","         5994,  7155,  4127,  5559,  2105,  2006,  2019, 18691,  3919, 16636,\n","         2953,  3698,  2040,  4241,  3775,  7699, 28667,  4221,  1037,  2261,\n","        26471,  3210,  2055,  1996,  3896,  1997,  8249,  2021,  1996,  3185,\n","         2515,  2025,  2729,  1010,  2428,  1012,  2009,  1005,  1055,  1037,\n","        11576,  2265,  1998,  1037, 28851,  2028,  2012,  2008,  2007,  1037,\n","        27873,  5305,  3168,  1997,  8562,  2005,  2216,  2040,  2064,  4308,\n","         2009,  1011,  1011,  2028,  2307,  4756,  3310,  2043,  1996, 13721,\n","         2158, 21811,  2015,  2588,  1037,  2402,  2611,  1999,  1996,  3224,\n","         1998,  2003,  2061,  2012,  1037,  3279,  2005,  2054,  2000,  2079,\n","         2008,  2028,  1997,  2010,  2159, 16949,  2041,  1012, 26316,  1012,\n","         1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  1996,   102])\n","torch.Size([])\n","tensor(1)\n"]},{"data":{"text/plain":["(None, None)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["iterdata = iter(train_loader)\n","text, label = next(iterdata)\n","print(text[0].shape), print(text[0]) \n","print(label[0].shape), print(label[0])"]},{"cell_type":"markdown","metadata":{"id":"i-FshZcTZBQ2"},"source":["## Self-attention -> Multi-head attention\n","\n","이번에는 self-attention을 구현해보겠습니다.\n","\n","Self-attention은 shape이 (B, S, D)인 embedding이 들어왔을 때 attention을 적용하여 새로운 representation을 만들어내는 module입니다.\n","\n","여기서 B는 batch size, S는 sequence length, D는 embedding 차원입니다.\n","\n","구현은 다음과 같습니다."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MBlMVMZcRAxv"},"outputs":[],"source":["from torch import nn\n","from math import sqrt\n","\n","# Single-head attention\n","class SelfAttention(nn.Module):\n","  def __init__(self, input_dim, d_model):\n","    super().__init__()\n","\n","    self.input_dim = input_dim # input dimension of an embedding vector\n","    self.d_model = d_model # the hidden layer size of the neural network\n","\n","    self.wq = nn.Linear(input_dim, d_model)\n","    self.wk = nn.Linear(input_dim, d_model)\n","    self.wv = nn.Linear(input_dim, d_model)\n","    self.dense = nn.Linear(d_model, d_model)\n","\n","    self.softmax = nn.Softmax(dim=-1)\n","\n","  def forward(self, x, mask):\n","    q, k, v = self.wq(x), self.wk(x), self.wv(x)\n","    score = torch.matmul(q, k.transpose(-1, -2)) # (B, S, D) * (B, D, S) = (B, S, S)\n","    score = score / sqrt(self.d_model)\n","\n","    if mask is not None:\n","      score = score + (mask * -1e9)\n","\n","    score = self.softmax(score)\n","    result = torch.matmul(score, v)\n","    result = self.dense(result)\n","\n","    return result\n","\n","# Multi-head attention\n","class MHA(nn.Module):\n","  def __init__(self, input_dim, d_model, n_head):\n","    super().__init__()\n","    assert d_model % n_head == 0, \"d_model must be divisible by n_heads\"\n","\n","    self.input_dim = input_dim\n","    self.d_model = d_model \n","    self.n_head = n_head \n","    self.depth = d_model // n_head\n","\n","    self.wq = nn.Linear(self.input_dim, self.d_model)\n","    self.wk = nn.Linear(self.input_dim, self.d_model)\n","    self.wv = nn.Linear(self.input_dim, self.d_model)\n","    self.dense = nn.Linear(self.d_model, self.d_model)\n","\n","    self.softmax = nn.Softmax(dim=-1)\n","  \n","  def split_heads(self, x):\n","    batch_s = x.size(0)\n","    x = x.view(batch_s, -1, self.n_head, self.depth)\n","    return x.transpose(1, 2)\n","\n","  def forward(self, x, mask):\n","    batch_s= x.size(0)\n","    q, k, v = self.wq(x), self.wk(x), self.wv(x)\n","\n","    # split output of lenear transformation\n","    q = self.split_heads(q) \n","    k = self.split_heads(k) \n","    v = self.split_heads(v) \n","    mask = mask.unsqueeze(1).expand(batch_s, self.n_head, -1, -1)\n","\n","    # Scaled Dot-Product Attention\n","    score = torch.matmul(q, k.transpose(-1, -2)) # (B, n_head, S, D) * (B, n_head, D, S) = (B, n_head, S, S)\n","    score = score / sqrt(self.depth) # scale the score to prevent vanishing gradient.\n","\n","    if mask is not None:\n","      score = score + (mask * -1e9) # Mask\n","\n","    score = self.softmax(score) \n","    result = torch.matmul(score, v)\n","\n","    # concat attentions  \n","    result = result.transpose(1,2).contiguous().view(batch_s, -1, self.d_model)\n","\n","    result = self.dense(result)\n","\n","    return result"]},{"cell_type":"markdown","metadata":{"id":"-S0vMp85ZRNO"},"source":["대부분은 Transformer 챕터에서 배운 수식들을 그대로 구현한 것에 불과합니다.\n","차이점은 `mask`의 존재여부입니다.\n","이전 챕터에서 우리는 가변적인 text data들에 padding token을 붙여 하나의 matrix로 만든 방법을 배웠습니다.\n","실제 attention 계산에서는 이를 무시해주기 위해 mask를 만들어 제공해주게 됩니다.\n","여기서 mask의 shape은 (B, S, 1)로, 만약 `mask[i, j] = True`이면 그 변수는 padding token에 해당한다는 뜻입니다.\n","이러한 값들을 무시해주는 방법은 shape이 (B, S, S)인 `score`가 있을 때(수업에서 배운 $A$와 동일) `score[i, j]`에 아주 작은 값을 더해주면 됩니다. 아주 작은 값은 예를 들어 `-1000..00 = -1e9` 같은 것이 있습니다.\n","이렇게 작은 값을 더해주고 나면 softmax를 거쳤을 때 0에 가까워지기 때문에 weighted sum 과정에서 padding token에 해당하는 `v` 값들을 무시할 수 있게 됩니다.\n","\n","다음은 multi-head attention과 feed-forward layer를 구현한 모습입니다."]},{"cell_type":"code","execution_count":4,"metadata":{"id":"VZHPCn9AS5Gp"},"outputs":[],"source":["class TransformerLayer(nn.Module):\n","  def __init__(self, input_dim, d_model, dff):\n","    super().__init__()\n","\n","    self.input_dim = input_dim\n","    self.d_model = d_model\n","    self.dff = dff\n","    self.n_head = 4\n","\n","    self.sa = MHA(input_dim, d_model, self.n_head)\n","\n","    self.ffn = nn.Sequential(\n","      nn.Linear(d_model, dff),\n","      nn.ReLU(),\n","      nn.Linear(dff, d_model)\n","    )\n","\n","    self.dropout = nn.Dropout(0.1)\n","    self.norm = nn.LayerNorm(d_model)\n","\n","  def forward(self, x, mask):\n","    x1 = self.sa(x, mask)\n","    x1 = self.dropout(x1)\n","    x = self.norm(x + x1)\n","\n","    x1 = self.ffn(x)\n","    x1 = self.dropout(x1)\n","    x = self.norm(x + x1)\n","\n","    return x"]},{"cell_type":"markdown","metadata":{"id":"O_xC9BQJaU4q"},"source":["보시다시피 self-attention의 구현이 어렵지, Transformer layer 하나 구현하는 것은 수업 때 다룬 그림과 크게 구분되지 않는다는 점을 알 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"J3VYrqTJagS1"},"source":["## Positional encoding\n","\n","이번에는 positional encoding을 구현합니다. Positional encoding의 식은 다음과 같습니다:\n","$$\n","\\begin{align*} PE_{pos, 2i} &= \\sin\\left( \\frac{pos}{10000^{2i/D}} \\right), \\\\ PE_{pos, 2i+1} &= \\cos\\left( \\frac{pos}{10000^{2i/D}} \\right).\\end{align*}\n","$$\n","\n","이를 Numpy로 구현하여 PyTorch tensor로 변환한 모습은 다음과 같습니다:"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1723896343031,"user":{"displayName":"조승혁","userId":"15759752471844115325"},"user_tz":-540},"id":"Uf_jMQWDUR79","outputId":"534712be-1522-4d32-81b7-87f50a6f1f2a"},"outputs":[],"source":["import numpy as np\n","\n","\n","def get_angles(pos, i, d_model):\n","    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n","    return pos * angle_rates\n","\n","def positional_encoding(position, d_model):\n","    angle_rads = get_angles(np.arange(position)[:, None], np.arange(d_model)[None, :], d_model)\n","    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n","    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n","    pos_encoding = angle_rads[None, ...]\n","\n","    return torch.FloatTensor(pos_encoding)\n","\n","\n","max_len = 400"]},{"cell_type":"markdown","metadata":{"id":"5unoDcBva3eN"},"source":["Positional encoding은 `angle_rads`를 구현하는 과정에서 모두 구현이 되었습니다. 여기서 `angle_rads`의 shape은 (S, D)입니다.\n","우리는 일반적으로 batch로 주어지는 shape이 (B, S, D)인 tensor를 다루기 때문에 마지막에 None을 활용하여 shape을 (1, S, D)로 바꿔주게됩니다.\n","\n","위에서 구현한 `TransformerLayer`와 positional encoding을 모두 합친 모습은 다음과 같습니다:"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"8MaiCGh8TsDH"},"outputs":[],"source":["class TextClassifier(nn.Module):\n","  def __init__(self, vocab_size, d_model, n_layers, d_ffn):\n","    super().__init__()\n","\n","    self.vocab_size = vocab_size\n","    self.d_model = d_model\n","    self.n_layers = n_layers\n","    self.d_ffn = d_ffn\n","\n","    self.embedding = nn.Embedding(vocab_size, d_model)\n","    self.pos_encoding = nn.parameter.Parameter(positional_encoding(max_len, d_model), requires_grad=False)\n","    self.layers = nn.ModuleList([TransformerLayer(d_model, d_model, d_ffn) for _ in range(n_layers)])\n","    self.classification = nn.Linear(d_model, 1)\n","\n","  def forward(self, x):\n","    mask = (x == tokenizer.pad_token_id)\n","    mask = mask[:, None, :]\n","    seq_len = x.shape[1]\n","\n","    x = self.embedding(x)\n","    x = x * sqrt(self.d_model)\n","    x = x + self.pos_encoding[:, :seq_len]\n","\n","    for layer in self.layers:\n","      x = layer(x, mask)\n","\n","    x = x[:, 0]\n","    x = self.classification(x)\n","\n","    return x\n","\n","\n","model = TextClassifier(len(tokenizer), 32, 5, 32)"]},{"cell_type":"markdown","metadata":{"id":"XXpjPWHjbUK8"},"source":["기존과 다른 점들은 다음과 같습니다:\n","1. `nn.ModuleList`를 사용하여 여러 layer의 구현을 쉽게 하였습니다.\n","2. Embedding, positional encoding, transformer layer를 거치고 난 후 마지막 label을 예측하기 위해 사용한 값은 `x[:, 0]`입니다. 기존의 RNN에서는 padding token을 제외한 마지막 token에 해당하는 representation을 사용한 것과 다릅니다. 이렇게 사용할 수 있는 이유는 attention 과정을 보시면 첫 번째 token에 대한 representation은 이후의 모든 token의 영향을 받습니다. 즉, 첫 번째 token 또한 전체 문장을 대변하는 의미를 가지고 있다고 할 수 있습니다. 그래서 일반적으로 Transformer를 text 분류에 사용할 때는 이와 같은 방식으로 구현됩니다."]},{"cell_type":"markdown","metadata":{"id":"QDq05OlAb2lB"},"source":["## 학습\n","\n","학습하는 코드는 기존 실습들과 동일하기 때문에 마지막 결과만 살펴보도록 하겠습니다."]},{"cell_type":"code","execution_count":7,"metadata":{"id":"YHVVsWBPQmnv","outputId":"64b5790f-7649-4a47-95f8-bebe158aba4f"},"outputs":[],"source":["from torch.optim import Adam\n","\n","lr = 0.001\n","model = model.to('cuda')\n","loss_fn = nn.BCEWithLogitsLoss()\n","\n","optimizer = Adam(model.parameters(), lr=lr)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"r88BALxO1zc1"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","def accuracy(model, dataloader):\n","  cnt = 0\n","  acc = 0\n","\n","  for data in dataloader:\n","    inputs, labels = data\n","    inputs, labels = inputs.to('cuda'), labels.to('cuda')\n","\n","    preds = model(inputs)\n","    # preds = torch.argmax(preds, dim=-1)\n","    preds = (preds > 0).long()[..., 0]\n","\n","    cnt += labels.shape[0]\n","    acc += (labels == preds).sum().item()\n","\n","  return acc / cnt"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":408929,"status":"ok","timestamp":1723896769492,"user":{"displayName":"조승혁","userId":"15759752471844115325"},"user_tz":-540},"id":"al_b56TYRILq","outputId":"90a56264-4ef3-4def-e7b7-df4b5cd3c305"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch   0 | Train Loss: 213.55119693279266\n","=========> Train acc: 0.822 | Test acc: 0.786\n","Epoch   1 | Train Loss: 146.27066114544868\n","=========> Train acc: 0.881 | Test acc: 0.825\n","Epoch   2 | Train Loss: 114.19156200438738\n","=========> Train acc: 0.922 | Test acc: 0.837\n","Epoch   3 | Train Loss: 92.38473325967789\n","=========> Train acc: 0.942 | Test acc: 0.834\n","Epoch   4 | Train Loss: 71.35810467973351\n","=========> Train acc: 0.951 | Test acc: 0.829\n","Epoch   5 | Train Loss: 53.305601278319955\n","=========> Train acc: 0.979 | Test acc: 0.833\n","Epoch   6 | Train Loss: 40.575129996053874\n","=========> Train acc: 0.984 | Test acc: 0.827\n","Epoch   7 | Train Loss: 30.78324707224965\n","=========> Train acc: 0.988 | Test acc: 0.827\n","Epoch   8 | Train Loss: 26.301936268340796\n","=========> Train acc: 0.990 | Test acc: 0.824\n","Epoch   9 | Train Loss: 23.284483833238482\n","=========> Train acc: 0.990 | Test acc: 0.827\n","Epoch  10 | Train Loss: 20.88277811743319\n","=========> Train acc: 0.989 | Test acc: 0.822\n","Epoch  11 | Train Loss: 18.932808955665678\n","=========> Train acc: 0.992 | Test acc: 0.825\n","Epoch  12 | Train Loss: 18.056516204727814\n","=========> Train acc: 0.994 | Test acc: 0.826\n","Epoch  13 | Train Loss: 15.710335298907012\n","=========> Train acc: 0.993 | Test acc: 0.826\n","Epoch  14 | Train Loss: 16.212357737356797\n","=========> Train acc: 0.992 | Test acc: 0.824\n","Epoch  15 | Train Loss: 13.77652661409229\n","=========> Train acc: 0.996 | Test acc: 0.828\n","Epoch  16 | Train Loss: 12.170765130547807\n","=========> Train acc: 0.995 | Test acc: 0.827\n","Epoch  17 | Train Loss: 12.364040931221098\n","=========> Train acc: 0.994 | Test acc: 0.824\n","Epoch  18 | Train Loss: 13.414262545062229\n","=========> Train acc: 0.995 | Test acc: 0.828\n","Epoch  19 | Train Loss: 12.087420763913542\n","=========> Train acc: 0.991 | Test acc: 0.823\n","Epoch  20 | Train Loss: 13.124127159826458\n","=========> Train acc: 0.995 | Test acc: 0.828\n","Epoch  21 | Train Loss: 11.469358461443335\n","=========> Train acc: 0.994 | Test acc: 0.822\n","Epoch  22 | Train Loss: 10.646359065081924\n","=========> Train acc: 0.995 | Test acc: 0.825\n","Epoch  23 | Train Loss: 9.899892976973206\n","=========> Train acc: 0.996 | Test acc: 0.824\n","Epoch  24 | Train Loss: 10.98117640381679\n","=========> Train acc: 0.996 | Test acc: 0.824\n","Epoch  25 | Train Loss: 9.920738434186205\n","=========> Train acc: 0.997 | Test acc: 0.828\n","Epoch  26 | Train Loss: 9.316088223364204\n","=========> Train acc: 0.997 | Test acc: 0.822\n","Epoch  27 | Train Loss: 9.49271293869242\n","=========> Train acc: 0.997 | Test acc: 0.823\n","Epoch  28 | Train Loss: 9.96093194722198\n","=========> Train acc: 0.996 | Test acc: 0.828\n","Epoch  29 | Train Loss: 9.445325488341041\n","=========> Train acc: 0.997 | Test acc: 0.828\n","Epoch  30 | Train Loss: 10.071011811727658\n","=========> Train acc: 0.996 | Test acc: 0.829\n","Epoch  31 | Train Loss: 9.14949070638977\n","=========> Train acc: 0.997 | Test acc: 0.827\n","Epoch  32 | Train Loss: 7.284531612065621\n","=========> Train acc: 0.997 | Test acc: 0.831\n","Epoch  33 | Train Loss: 9.88064077286981\n","=========> Train acc: 0.997 | Test acc: 0.831\n","Epoch  34 | Train Loss: 9.298044369672425\n","=========> Train acc: 0.996 | Test acc: 0.831\n","Epoch  35 | Train Loss: 8.877095763920806\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     24\u001b[0m   model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 25\u001b[0m   train_acc\u001b[38;5;241m.\u001b[39mappend(\u001b[43maccuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     26\u001b[0m   test_acc\u001b[38;5;241m.\u001b[39mappend(accuracy(model, test_loader))\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=========> Train acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Test acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[8], line 18\u001b[0m, in \u001b[0;36maccuracy\u001b[0;34m(model, dataloader)\u001b[0m\n\u001b[1;32m     15\u001b[0m   preds \u001b[38;5;241m=\u001b[39m (preds \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mlong()[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     17\u001b[0m   cnt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 18\u001b[0m   acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acc \u001b[38;5;241m/\u001b[39m cnt\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["n_epochs = 50\n","\n","train_acc = []\n","test_acc = []\n","\n","for epoch in range(n_epochs):\n","  total_loss = 0.\n","  model.train()\n","  for data in train_loader:\n","    model.zero_grad()\n","    inputs, labels = data\n","    inputs, labels = inputs.to('cuda'), labels.to('cuda').float()\n","\n","    preds = model(inputs)[..., 0]\n","    loss = loss_fn(preds, labels)\n","    loss.backward()\n","    optimizer.step()\n","\n","    total_loss += loss.item()\n","\n","  print(f\"Epoch {epoch:3d} | Train Loss: {total_loss}\")\n","\n","  with torch.no_grad():\n","    model.eval()\n","    train_acc.append(accuracy(model, train_loader))\n","    test_acc.append(accuracy(model, test_loader))\n","    print(f\"=========> Train acc: {train_acc[-1]:.3f} | Test acc: {test_acc[-1]:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"WqZays2yb8Ja"},"source":["학습이 안정적으로 진행되며 RNN보다 빨리 수렴하는 것을 확인할 수 있습니다.\n","\n","하지만 test 정확도가 RNN보다 낮은 것을 보았을 때, overfitting에 취약하다는 것을 알 수 있습니다."]},{"cell_type":"code","execution_count":10,"metadata":{"id":"NAXB6GgIQy1S"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Max accuercy with train set: 99.748%\n","Max accuercy with test set: 83.664%\n"]}],"source":["import numpy as np\n","\n","def plot_acc(train_accs, test_accs, label1='train', label2='test'):\n","  x = np.arange(len(train_accs))\n","\n","  plt.plot(x, train_accs, label=label1)\n","  plt.plot(x, test_accs, label=label2)\n","  plt.legend()\n","  plt.show()\n","\n","plot_acc(train_acc, test_acc)\n","\n","print(f'Max accuercy with train set: {max(train_acc)*100.}%')\n","print(f'Max accuercy with test set: {max(test_acc)*100.}%')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}
